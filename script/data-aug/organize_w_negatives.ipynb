{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Answers\n",
      "Read Negatives Matrix\n",
      "Read Questions\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import _pickle as cPickle\n",
    "import os\n",
    "\n",
    "# decontract, depunctuate\n",
    "filter_type = \"dcp\"\n",
    "\n",
    "# sampling: [\"top\", \"random\"]\n",
    "sampling_type = \"random\"\n",
    "\n",
    "# Dumping Paths\n",
    "que_split_path_dict = {\n",
    "    \"val\": (\"../../datasets/VQA/back-translate/bt_fil_{}_sampling_{}_v2_OpenEnded_mscoco_val2014_questions.pkl\".format(filter_type, sampling_type),\n",
    "            \"../../datasets/VQA/v2_OpenEnded_mscoco_val2014_questions.json\"),\n",
    "    \"train\": (\"../../datasets/VQA/back-translate/bt_fil_{}_sampling_{}_v2_OpenEnded_mscoco_train2014_questions.pkl\".format(filter_type, sampling_type),\n",
    "              \"../../datasets/VQA/v2_OpenEnded_mscoco_train2014_questions.json\"),\n",
    "}\n",
    "\n",
    "\n",
    "ans_split_path_dict = {\n",
    "    \"val\": (\"../../datasets/VQA/back-translate/bt_fil_{}_sampling_{}_val_target.pkl\".format(filter_type, sampling_type),\n",
    "            \"../../datasets/VQA/cache/val_target.pkl\"),\n",
    "    \"train\": (\"../../datasets/VQA/back-translate/bt_fil_{}_sampling_{}_train_target.pkl\".format(filter_type, sampling_type),\n",
    "              \"../../datasets/VQA/cache/train_target.pkl\"),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "ans2label_path = os.path.join(\"../../datasets/VQA/\", \"cache\", \"trainval_ans2label.pkl\")\n",
    "label2ans_path = os.path.join(\"../../datasets/VQA/\", \"cache\", \"trainval_label2ans.pkl\")\n",
    "ans2label = cPickle.load(open(ans2label_path, \"rb\"))\n",
    "label2ans = cPickle.load(open(label2ans_path, \"rb\"))\n",
    "answer_dict = {}\n",
    "# use later\n",
    "answers_data = []\n",
    "for key in ans_split_path_dict.keys():\n",
    "    path = ans_split_path_dict[key][0]\n",
    "    answers = cPickle.load(open(path, \"rb\"))\n",
    "    answers_data.append(answers)\n",
    "    answers = list(itertools.chain.from_iterable(answers))\n",
    "    for ans in answers:\n",
    "        answer_dict[ans[\"question_id\"]] = ans[\"labels\"]\n",
    "print(\"Read Answers\")\n",
    "\n",
    "negs_path = \"../../datasets/VQA/back-translate/train_val_question_negs_fil_{}_sampling_{}.pkl\" \\\n",
    "    .format(filter_type, sampling_type)\n",
    "negs_data = cPickle.load(open(negs_path, \"rb\"))\n",
    "negs_dict = {}\n",
    "for qid, sim_scores, sim_qids in zip(negs_data[\"qids\"], negs_data[\"sim_scores\"], negs_data[\"sim_qids\"]):\n",
    "    negs_dict[qid] = (sim_scores, sim_qids)\n",
    "print(\"Read Negatives Matrix\")\n",
    "\n",
    "# create dicts\n",
    "image_dict = defaultdict(list)\n",
    "questions_rephrasings = defaultdict(list)\n",
    "question_dict = {}\n",
    "\n",
    "# use later\n",
    "questions_data = []\n",
    "qids_dict = {}\n",
    "for split, que_path in que_split_path_dict.items():\n",
    "    data = cPickle.load(open(que_path[0], \"rb\"))\n",
    "    questions_data.append(data)\n",
    "    questions_list = data[\"questions\"]\n",
    "    _dict = {}\n",
    "    \n",
    "    # add \"rephrasing_of\" key\n",
    "    for _questions in questions_list:\n",
    "        # only keep the min-qid in same-image ids\n",
    "        min_qid = min([x['question_id'] for x in _questions])\n",
    "        assert len(set([x['image_id'] for x in _questions])) == 1\n",
    "        image_dict[_questions[0][\"image_id\"]].append(min_qid)\n",
    "        for _que in _questions:\n",
    "            question_dict[_que[\"question_id\"]] = _que[\"question\"]\n",
    "            _dict[_que[\"question_id\"]] = None\n",
    "    qids_dict[split] = _dict\n",
    "print(\"Read Questions\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_negs_dict_train = {}\n",
    "save_negs_dict_val = {}\n",
    "save_negs_dict_trainval = {}\n",
    "\n",
    "def filter_negatives(sample):\n",
    "    # filter same-image questions\n",
    "    save_dict = {}\n",
    "    same_image_ids = image_dict[sample[\"image_id\"]]\n",
    "    fil_same_image_ids = []\n",
    "    ref_answers = answer_dict[sample[\"question_id\"]]\n",
    "    for qid in same_image_ids:\n",
    "        if qid == sample[\"question_id\"]:\n",
    "            continue\n",
    "        cand_answers = answer_dict[qid]\n",
    "        if len(set(ref_answers).intersection(set(cand_answers))) == 0:\n",
    "            fil_same_image_ids.append(qid)\n",
    "    save_dict[\"same_image_questions_neg\"] = fil_same_image_ids\n",
    "\n",
    "    # filter top-k questions\n",
    "    if sample[\"question_id\"] not in negs_dict:\n",
    "        return True\n",
    "\n",
    "    top_k_sim_scores, top_k_questions = negs_dict[sample[\"question_id\"]]\n",
    "    fil_top_k_questions = []\n",
    "    fil_top_k_questions_train = []\n",
    "    fil_top_k_questions_val = []\n",
    "    \n",
    "    for qid in top_k_questions:\n",
    "        cand_answers = answer_dict[qid]\n",
    "        if len(set(ref_answers).intersection(set(cand_answers))) == 0:\n",
    "            fil_top_k_questions.append(qid)\n",
    "            if qid in qids_dict[\"train\"]:\n",
    "                fil_top_k_questions_train.append(qid)\n",
    "            elif qid in qids_dict[\"val\"]:\n",
    "                fil_top_k_questions_val.append(qid)\n",
    "            else:\n",
    "                import pdb\n",
    "                pdb.set_trace()\n",
    "    \n",
    "    save_dict[\"top_k_questions_neg\"] = fil_top_k_questions\n",
    "    save_dict[\"top_k_questions_neg_train\"] = fil_top_k_questions_train\n",
    "    save_dict[\"top_k_questions_neg_val\"] = fil_top_k_questions_val\n",
    "\n",
    "    if sample[\"question_id\"] in qids_dict[\"train\"]:\n",
    "        del save_dict[\"top_k_questions_neg_val\"]\n",
    "        save_negs_dict_trainval[sample[\"question_id\"]] = save_dict\n",
    "        save_negs_dict_train[sample[\"question_id\"]] = save_dict\n",
    "    elif sample[\"question_id\"] in qids_dict[\"val\"]:\n",
    "        del save_dict[\"top_k_questions_neg_train\"]\n",
    "        save_negs_dict_trainval[sample[\"question_id\"]] = save_dict\n",
    "        save_negs_dict_val[sample[\"question_id\"]] = save_dict\n",
    "    else:\n",
    "        import pdb\n",
    "        pdb.set_trace() \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions Path:  ../../datasets/VQA/back-translate/bt_fil_dcp_sampling_random_v2_OpenEnded_mscoco_val2014_questions.pkl\n",
      "Answers Path:  ../../datasets/VQA/back-translate/bt_fil_dcp_sampling_random_val_target.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 214354/214354 [19:32<00:00, 182.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions Path:  ../../datasets/VQA/back-translate/bt_fil_dcp_sampling_random_v2_OpenEnded_mscoco_train2014_questions.pkl\n",
      "Answers Path:  ../../datasets/VQA/back-translate/bt_fil_dcp_sampling_random_train_target.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 443757/443757 [39:29<00:00, 187.30it/s]  \n"
     ]
    }
   ],
   "source": [
    "for que_data, ans_data, que_path, ans_path in zip(questions_data, \n",
    "                                                  answers_data, \n",
    "                                                  que_split_path_dict.values(), \n",
    "                                                  ans_split_path_dict.values()):\n",
    "    data, answers, que_path, ans_path = que_data,\\\n",
    "                                        ans_data,\\\n",
    "                                        que_path[0],\\\n",
    "                                        ans_path[0]\n",
    "    \n",
    "    print(\"Questions Path: \", que_path)\n",
    "    print(\"Answers Path: \", ans_path)\n",
    "    questions_list = data[\"questions\"]\n",
    "\n",
    "    # add \"rephrasing_of\" key\n",
    "    for _questions in questions_list:\n",
    "        rep_id = min([s['question_id'] for s in _questions])\n",
    "        for _que in _questions:\n",
    "            _que[\"rephrasing_of\"] = rep_id\n",
    "    \n",
    "    assert len(questions_list) == len(answers)\n",
    "\n",
    "    # remove questions w/o negatives\n",
    "    for idx in tqdm(range(len(questions_list)), total=len(questions_list)):\n",
    "        _updated_ques = []\n",
    "        _updated_answers = []\n",
    "        _questions = questions_list[idx]\n",
    "        _answers = answers[idx]\n",
    "\n",
    "        for _que, _ans in zip(_questions, _answers):\n",
    "            delete = filter_negatives(_que)\n",
    "            if not delete:\n",
    "                _updated_ques.append(_que)\n",
    "                _updated_answers.append(_ans)\n",
    "            else:\n",
    "                import pdb\n",
    "                pdb.set_trace()\n",
    "        questions_list[idx] = _updated_ques\n",
    "        answers[idx] = _updated_answers\n",
    "\n",
    "# This was a hacky filtering procedure for removing unused samples, not needed any further.\n",
    "#     cPickle.dump(data, open(que_path, \"wb\"), protocol=2)\n",
    "#     cPickle.dump(answers, open(ans_path, \"wb\"), protocol=2)\n",
    "#     print(f\"Dumped: {que_path}\")\n",
    "#     print(f\"Dumped: {ans_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_negs_paths = {\n",
    "   \"val\": \"../../datasets/VQA/back-translate/fil_{}_sampling_{}_val_question_negs.pkl\".format(filter_type, sampling_type),\n",
    "   \"train\": \"../../datasets/VQA/back-translate/fil_{}_sampling_{}_train_question_negs.pkl\".format(filter_type, sampling_type),\n",
    "   \"trainval\": \"../../datasets/VQA/back-translate/fil_{}_sampling_{}_trainval_question_negs.pkl\".format(filter_type, sampling_type),               \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = list(save_negs_dict_val.values())\n",
    "lens = [len(x[\"top_k_questions_neg\"]) for x in values]\n",
    "max(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Path: ../../datasets/VQA/back-translate/fil_dcp_sampling_random_val_question_negs.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 810454/810454 [00:18<00:00, 44905.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Path: ../../datasets/VQA/back-translate/fil_dcp_sampling_random_train_question_negs.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1680018/1680018 [00:57<00:00, 29098.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Path: ../../datasets/VQA/back-translate/fil_dcp_sampling_random_trainval_question_negs.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2490472/2490472 [01:12<00:00, 34304.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# not saved \"trainval\" file\n",
    "for key in save_negs_paths.keys():\n",
    "    negs_dict = globals()[f\"save_negs_dict_{key}\"]\n",
    "    print(f\"Save Path: {save_negs_paths[key]}\")\n",
    "\n",
    "    question_ids = list(negs_dict.keys())\n",
    "    question_values = list(negs_dict.values())\n",
    "    question_negs = np.zeros((len(question_ids), 300), dtype=np.int64) + -1\n",
    "    same_image_questions_neg = np.zeros((len(question_ids), 300), dtype=np.int64) + -1\n",
    "\n",
    "    for idx in tqdm(range(len(question_negs))):\n",
    "        if key == \"trainval\":\n",
    "            negs_ids = question_values[idx][f\"top_k_questions_neg\"]\n",
    "        else:\n",
    "            neg_ids = question_values[idx][f\"top_k_questions_neg_{key}\"]\n",
    "        same_image_ids = question_values[idx][\"same_image_questions_neg\"]\n",
    "        question_negs[idx][:len(neg_ids)] = neg_ids\n",
    "        try:\n",
    "            same_image_questions_neg[idx][:len(same_image_ids)] = same_image_ids\n",
    "        except:\n",
    "            import pdb\n",
    "            pdb.set_trace()\n",
    "    \n",
    "    cPickle.dump({\"qids\": question_ids, \n",
    "                \"question_negs\": question_negs, \n",
    "                \"same_image_questions_neg\": same_image_questions_neg}, \n",
    "         open(save_negs_paths[key], \"wb\"), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
