{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import pdb\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from bisect import bisect\n",
    "import yaml\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vilbert.task_utils import (\n",
    "    LoadDatasets,\n",
    "    LoadLosses,\n",
    "    ForwardModelsTrain,\n",
    "    ForwardModelsVal,\n",
    "    clip_gradients,\n",
    "    get_optim_scheduler)\n",
    "\n",
    "import vilbert.utils as utils\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python train_tasks_evaluate.py \\\n",
    "# --task_file sweeps/m4c-spatial-mask-1-2-layers-4.yml \\\n",
    "# --from_scratch \\\n",
    "# --resume_file save/TextVQA_spatial_m4c_mmt_textvqa-finetune_from_multi_task_model-local-spatial-4layers-mask-1-2/pytorch_ckpt_latest.tar \\\n",
    "# --config_file config/spatial_m4c_mmt_textvqa.json \\\n",
    "# --tasks 19 \\\n",
    "# --train_iter_gap 4 --save_name finetune_from_multi_task_model \\\n",
    "# --tag \"debug\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = edict({\n",
    "    'bert_model': 'bert-base-uncased',\n",
    "    'tasks': '19',\n",
    "    'do_lower_case': True, \n",
    "    'in_memory': True,\n",
    "    'gradient_accumulation_steps': 1, \n",
    "    'num_workers': 0, \n",
    "    'local_rank': -1, \n",
    "    'clean_train_sets': False, \n",
    "    'num_train_epochs': 100,\n",
    "    'train_iter_multiplier': 1.0, \n",
    "    'config_file': \"config/spatial_m4c_mmt_textvqa.json\",\n",
    "    'resume_file': \"save/TextVQA_spatial_m4c_mmt_textvqa-finetune_from_multi_task_model-local-spatial-4layers-mask-1-2/pytorch_ckpt_latest.tar\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vilbert.m4c_spatial import BertConfig, M4C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '/srv/share/ykant3/common/vilbert-multi-task/'\n",
    "task_file = 'sweeps/m4c-spatial-mask-1-2-layers-4.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(task_file, \"r\") as f:\n",
    "        task_cfg = edict(yaml.safe_load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    task_batch_size, \n",
    "    task_num_iters, \n",
    "    task_ids, \n",
    "    task_datasets_train, \n",
    "    task_datasets_val, \n",
    "    task_dataloader_train, \n",
    "    task_dataloader_val\n",
    ") = LoadDatasets(args, task_cfg, args.tasks.split(\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_losses = LoadLosses(args, task_cfg, args.tasks.split(\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"TASK\" + str(args.tasks)\n",
    "task_id = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_keys = [\"attention_mask_quadrants\", \"hidden_size\", \"num_implicit_relations\", \"spatial_type\", \"num_hidden_layers\", \"num_spatial_layers\", \"layer_type_list\"]\n",
    "transfer_keys.extend([\"aux_spatial_fusion\", \"use_aux_heads\"])\n",
    "\n",
    "with open(args.config_file, \"r\") as file:\n",
    "    config_dict = json.load(file)\n",
    "\n",
    "# Adding blank keys that could be dynamically replaced later\n",
    "config_dict[\"layer_type_list\"] = None\n",
    "\n",
    "# Replace keys\n",
    "for key in transfer_keys:\n",
    "    if key in task_cfg[\"TASK19\"]:\n",
    "        config_dict[key] = task_cfg[\"TASK19\"][key]\n",
    "        logger.info(f\"Transferring keys:  {key}, {config_dict[key]}\")\n",
    "mmt_config = BertConfig.from_dict(config_dict)\n",
    "\n",
    "text_bert_config = BertConfig.from_json_file(\"config/m4c_textbert_textvqa.json\")\n",
    "model = M4C(mmt_config, text_bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Resuming from Checkpoint: {args.resume_file}\")\n",
    "checkpoint = torch.load(args.resume_file, map_location=\"cpu\")\n",
    "new_dict = {}\n",
    "for attr in checkpoint[\"model_state_dict\"]:\n",
    "    if attr.startswith(\"module.\"):\n",
    "        new_dict[attr.replace(\"module.\", \"\", 1)] = checkpoint[\n",
    "            \"model_state_dict\"\n",
    "        ][attr]\n",
    "    else:\n",
    "        new_dict[attr] = checkpoint[\"model_state_dict\"][attr]\n",
    "model.load_state_dict(new_dict)\n",
    "del checkpoint\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    args,\n",
    "    task_dataloader_val,\n",
    "    task_stop_controller,\n",
    "    task_cfg,\n",
    "    device,\n",
    "    task_id,\n",
    "    model,\n",
    "    task_losses\n",
    "):\n",
    "\n",
    "    predictions = []\n",
    "    scores = 0.0\n",
    "    data_size = 0\n",
    "    model.eval()\n",
    "\n",
    "    for i, batch in enumerate(task_dataloader_val[task_id]):\n",
    "        # batch['spatial_adj_matrix'] = torch.zeros_like(batch['spatial_adj_matrix'])\n",
    "        # batch['spatial_adj_matrix'] = torch.ones_like(batch['spatial_adj_matrix'])\n",
    "        # batch['spatial_adj_matrix'] = torch.transpose(batch['spatial_adj_matrix'], 2, 1)\n",
    "\n",
    "        loss, score, batch_size,  batch_dict = ForwardModelsVal(\n",
    "            args, task_cfg, device, task_id, batch, model, task_losses\n",
    "        )\n",
    "\n",
    "        scores += score * batch_size\n",
    "        data_size += batch_size\n",
    "        \n",
    "        save_keys = ['question_id', 'textvqa_scores', 'targets']\n",
    "\n",
    "        batch_dict_keys = list(batch_dict.keys())\n",
    "        for key in batch_dict_keys:\n",
    "            if key not in save_keys:\n",
    "                del batch_dict[key]\n",
    "            else:\n",
    "                batch_dict[key] = batch_dict[key].cpu().detach().numpy()\n",
    "\n",
    "            predictions.append(batch_dict)\n",
    "\n",
    "        sys.stdout.write(\"%d/%d\\r\" % (i, len(task_dataloader_val[task_id])))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    print(\"Val Score: \", float(scores)/data_size)\n",
    "    \n",
    "    model.train()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_val_score = evaluate(\n",
    "        args,\n",
    "        task_dataloader_val,\n",
    "        None,\n",
    "        task_cfg,\n",
    "        device,\n",
    "        task,\n",
    "        model,\n",
    "        task_losses\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pad_obj_features', 'pad_obj_mask', 'pad_obj_bboxes', 'pad_ocr_features', 'pad_ocr_mask', 'pad_ocr_bboxes', 'segment_ids', 'co_attention_mask', 'question', 'question_id', 'image_id', 'answers', 'image_height', 'image_width', 'question_indices', 'num_question_tokens', 'question_mask', 'ocr_fasttext', 'ocr_tokens', 'ocr_length', 'ocr_phoc', 'spatial_adj_matrix', 'targets', 'train_prev_inds', 'train_loss_mask', 'train_acc_mask', 'spatial_loss_mask', 'spatial_ocr_relations'])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(task_dataloader_val[task]):\n",
    "    print(batch.keys())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(40)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(batch['question'][0] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1]],\n",
       "\n",
       "        [[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['co_attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 101, 2054, 2003, 1996, 4435, 1997, 2023, 4950, 1029,  102,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " tensor(10),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['question_indices'][0], batch['num_question_tokens'][0], batch['question_mask'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
